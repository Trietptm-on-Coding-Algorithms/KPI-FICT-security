import re
import functions as fn
import numpy as np

cipher = 'EFFPQLEKVTVPCPYFLMVHQLUEWCNVWFYGHYTCETHQEKLPVMSAKSPVPAPVYWMVHQLUSPQLYWLASLFVWPQLMVHQLUPLRPSQLULQESPBLWPCSVRVWFLHLWFLWPUEWFYOTCMQYSLWOYWYETHQEKLPVMSAKSPVPAPVYWHEPPLUWSGYULEMQTLPPLUGUYOLWDTVSQETHQEKLPVPVSMTLEUPQEPCYAMEWWYOYULULTCYWPQLSEOLSVOHTLUYAPVWLYGDALSSVWDPQLNLCKCLRQEASPVILSLEUMQBQVMQCYAHUYKEKTCASLFPYFLMVHQLUPQVSHEUEDUEHQBVTTPQLVWFLRYGMYVWMVFLWMLSPVTTBYUNESESADDLSPVYWCYAMEWPUCPYFVIVFLPQLOLSSEDLVWHEUPSKCPQLWAOKLUYGMQEUEMPLUSVWENLCEWFEHHTCGULXALWMCEWETCSVSPYLEMQYGPQLOMEWCYAGVWFEBECPYASLQVDQLUYUFLUGULXALWMCSPEPVSPVMSBVPQPQVSPCHLYGMVHQLUPQLWLRPHEUEDUEHQMYWPEVWSSYOLHULPPCVWPLULSPVWDVWGYUOEPVYWEKYAPSYOLEFFVPVYWETULBEUF'
plain_text = 'ADDTHEABILITYTODECIPHERANYKINDOFPOLYALPHABETICSUBSTITUTIONCIPHERSTHEONEUSEDINTHECIPHERTEXTSHEREHASTWENTYSIXINDEPENDENTRANDOMLYCHOSENMONOALPHABETICSUBSTITUTIONPATTERNSFOREACHLETTERFROMENGLISHALPHABETITISCLEARTHATYOUCANNOMORERELYONTHESAMESIMPLEROUTINEOFGUESSINGTHEKEYBYEXHAUSTIVESEARCHWHICHYOUPROBABLYUSEDTODECIPHERTHISPARAGRAPHWILLTHEINDEXOFCOINCIDENCESTILLWORKASASUGGESTIONYOUCANTRYTODIVIDETHEMESSAGEINPARTSBYTHENUMBEROFCHARACTERSINAKEYANDAPPLYFREQUENCYANALYSISTOEACHOFTHEMCANYOUFINDAWAYTOUSEHIGHERORDERFREQUENCYSTATISTICSWITHTHISTYPEOFCIPHERTHENEXTPARAGRAPHCONTAINSSOMEPRETTYINTERESTINGINFORMATIONABOUTSOMEADDITIONALREWARD'
plain_text_2_noisy = 'Studies that estimate and ran the most common words in English examine texts written in English. Perhaps the most comprehensive such analysis is one that was conducted against the Oxford English Corpus (OEC), a very large collection of texts from around the world that are written in the English language. A text corpus is a large collection of written works that are organised in a way that makes such analysis easier.'

# line = 'CKRCeMeCNeQeBtTNBeFHeeYtePtHQMeEQLFPBTBKDYeKTMJeGRUNCtWeCtFCCMeKtIthGLMEeBZTDYYEtUMRTUDeGTeCDFZRFKUNALMItUFStYLHOXTCLItTDFeKtttSBBeeBXZRSFMWtLYCeXFhYeDHQMBeBtHLITDeWQTLeeXLGtDMeKDeDAQeBtTNWBHhettTAeZEOeRKDItGBXBtFtTNOTYtABtGtQMHOEttheDXGACeCeYtDYMTLtTNALMIttTCFOFheeSGBXBttIeNRtMhQOUeFteKtPFSLeYtIKLGQFPNeQMthMMDAOtEDOCLONTLKeeCGUMEheHhTtLtTOMItMYeNeeNGPSCERtheKJSTWttheWSINeLCTDMeBWLYTCRBKUtheHCPPeOTLtGeBZTNBYhAeDHtIReBIYDQFLLOOCGhTSPtIWKQLFGeeHhKeQeBetTGLCEeBZTNeFTTFPHtMYGDHGCCTeCDFYeWOtteeHhTFWHSItOKRetheBSDSHLNtZOtUMEheHthBYttheLStZDQtMGQODMYBeKDReKSHFTheDEYBDHBeWNTWtthLtNNKHNAKMTeMMTFttLLKQeCeCeSHFMYTSteKYNQLWKWKHLYTCtDRYNUFZZCNDLTFeNRtFteTWAQMCeSUFTPRthFMZDtQZSLMZStWtTAPHLFeYRBKUtheDLFtBLBTPSQNTEBKNCLBSPePtEBKPSQHRCePBeFMMJOeBHQBSttheEhLFhtMJetMSeeHFAtBeTDtFXeKULeBWLCIYeNeBStNHeGeYhTFPZDFeKSLeLFQtHO'

# path = r'E:\Study\Универ\4-й курс\Безопасность\lab1\words_match.txt'

# with open(path, 'r') as g:
#     for line in g:
#         # print(re.findall('[^\s]((\w)\1{2})the', line))
#         print(re.findall('(\w)\1{2,}', line))

# candidates = set([l[1] for l in re.findall('t[A-Z]', line)])
# print(''.join(candidates))


# def cleanup(noisy_text):
#     clean_text = []
#     for l in noisy_text:
#         if l.isalpha():
#             clean_text.append(l)
#     clean_string = ''.join(clean_text)
#     return clean_string.upper()

# plain_text_2 = cleanup(plain_text_2_noisy)

print(fn.scoreOnTrigrams(cipher))
print(fn.scoreOnTrigrams(plain_text))
print(fn.scoreOnTrigrams(fn.cleanupNoisyText(plain_text_2_noisy)))

# test = [1, 2, 3]
# result = np.random.choice(test, 18)
# print(result)

# lst = list(range(1, 11))
# print(lst)
# print(lst[0:5])
